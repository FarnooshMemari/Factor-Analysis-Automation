{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb4b6b2b",
   "metadata": {},
   "source": [
    "# Factor Analysis Automation Tool\n",
    "\n",
    "This Jupyter Notebook automates the process of Exploratory and Confirmatory Factor Analysis (EFA/CFA) \n",
    "by selecting optimal item groupings, computing factor loadings, and evaluating model fit indices. \n",
    "\n",
    "## Features:\n",
    "- Performs **factor analysis** using the `factor_analyzer` library.\n",
    "- Selects item combinations based on construct prefixes.\n",
    "- Computes **factor loadings**, **correlation matrices**, and **covariance matrices**.\n",
    "- Evaluates **model fit indices** (Chi-Square, AVE, Composite Reliability, etc.).\n",
    "- Stores **results in Excel files** for further interpretation.\n",
    "\n",
    "## Requirements:\n",
    "Before running this notebook, install the required libraries:\n",
    "```sh\n",
    "pip install pandas numpy factor-analyzer openpyxl\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd37bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from openpyxl import Workbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e41705",
   "metadata": {},
   "source": [
    "## User Input\n",
    "\n",
    "The user needs to provide:\n",
    "1. The **survey dataset** file (Excel format).\n",
    "2. The **number of factors** to extract.\n",
    "3. The **minimum number of items per construct**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ecb586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"Survey_Data.xlsx\"  # Update the file path as needed\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Get user input for factor analysis\n",
    "num_factors = int(input(\"Enter the number of factors: \"))\n",
    "min_items_per_construct = int(input(\"Enter the minimum number of items per construct: \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25b7f93",
   "metadata": {},
   "source": [
    "## Factor Analysis Process\n",
    "\n",
    "1. Extracts construct prefixes from item names.\n",
    "2. Randomly selects valid combinations of items.\n",
    "3. Performs **factor analysis** with **varimax rotation**.\n",
    "4. Computes factor loadings, correlations, and model fit metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb29fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract construct prefixes from column names\n",
    "constructs = {}\n",
    "for col in df.columns:\n",
    "    prefix = ''.join(filter(str.isalpha, col))  # Extract only alphabetical prefix\n",
    "    if prefix not in constructs:\n",
    "        constructs[prefix] = []\n",
    "    constructs[prefix].append(col)\n",
    "\n",
    "# Filter constructs to ensure a minimum number of items\n",
    "valid_constructs = {k: v for k, v in constructs.items() if len(v) >= min_items_per_construct}\n",
    "\n",
    "# Generate valid unique item groupings (randomly sampled)\n",
    "max_combinations = 1000  # Limit to avoid excessive runtime\n",
    "valid_combinations = set()\n",
    "\n",
    "while len(valid_combinations) < max_combinations:\n",
    "    selected_items = []\n",
    "    for construct, items in valid_constructs.items():\n",
    "        size = random.randint(min_items_per_construct, len(items))  # Select at least min_items_per_construct\n",
    "        selected_items.extend(random.sample(items, size))\n",
    "    valid_combinations.add(tuple(sorted(selected_items)))  # Ensure uniqueness\n",
    "\n",
    "# Convert set back to list for processing\n",
    "valid_combinations = [list(comb) for comb in valid_combinations]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d4012b",
   "metadata": {},
   "source": [
    "## Saving Results\n",
    "\n",
    "- **Factor Loadings** are stored in an Excel file.\n",
    "- **Full Model Results** (Factor Loadings, Fit Indices, Correlations, and Covariance Matrices) are stored separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f596d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files\n",
    "wb_loadings = Workbook()\n",
    "del wb_loadings[wb_loadings.sheetnames[0]]  # Remove default sheet\n",
    "\n",
    "wb_full = Workbook()\n",
    "del wb_full[wb_full.sheetnames[0]]  # Remove default sheet\n",
    "\n",
    "# Sort models by variance explained and keep the top 50\n",
    "model_scores.sort(reverse=True, key=lambda x: x[0] if x[0] != \"NA\" else 0)\n",
    "top_models = model_scores[:50]\n",
    "\n",
    "# Save factor loadings to the first file\n",
    "for i, (score, items, loadings, fit_indices, construct_metrics, correlation_matrix, covariance_matrix) in enumerate(top_models):\n",
    "    sheet_name = f\"Top_{i+1}\"\n",
    "    ws = wb_loadings.create_sheet(title=sheet_name)\n",
    "    ws.append([\"Item\"] + [f\"Factor {j+1}\" for j in range(num_factors)])\n",
    "    for idx, row in loadings.iterrows():\n",
    "        ws.append([idx] + list(row))\n",
    "\n",
    "wb_loadings.save(\"Factor_Loadings.xlsx\")\n",
    "\n",
    "# Save full model results to the second file\n",
    "wb_full.save(\"Measurement_Model.xlsx\")\n",
    "\n",
    "print(\"Factor Loadings saved as 'Factor_Loadings.xlsx'\")\n",
    "print(\"Full results saved as 'Measurement_Model.xlsx'\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
